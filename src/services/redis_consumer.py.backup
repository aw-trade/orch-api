"""Redis stream consumer for trading simulation data"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import redis.asyncio as redis
from redis.exceptions import ConnectionError, ResponseError

from ..core.config import get_config
from .database_service import DatabaseService

logger = logging.getLogger(__name__)

class RedisStreamConsumer:
    """Redis stream consumer for real-time trading data"""
    
    def __init__(self, database_service: DatabaseService):
        self.config = get_config()
        self.database_service = database_service
        self.redis_client: Optional[redis.Redis] = None
        self.consumer_group = "trading-api-group"
        self.consumer_name = "trading-api-consumer"
        self.running = False
        
        # Consumer statistics
        self.stats = {
            "messages_processed": 0,
            "messages_failed": 0,
            "last_message_time": None,
            "database_write_success": 0,
            "database_write_failures": 0,
            "start_time": None,
            "last_error": None,
            "message_types": {
                "live_stats": 0,
                "final_results": 0,
                "trade_event": 0,
                "unknown": 0
            }
        }
        
    async def connect(self) -> bool:
        """Connect to Redis and initialize consumer group"""
        try:
            self.redis_client = redis.Redis(
                host=self.config.database.redis_host,
                port=self.config.database.redis_port,
                decode_responses=True
            )
            
            # Test connection
            await self.redis_client.ping()
            logger.info(f"âœ… Connected to Redis at {self.config.database.redis_host}:{self.config.database.redis_port}")
            
            # Verify or create consumer group
            if not await self._ensure_consumer_group():
                logger.error("âŒ Failed to initialize consumer group")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to connect to Redis: {e}")
            return False
    
    async def _ensure_consumer_group(self) -> bool:
        """Ensure consumer group exists and is properly configured"""
        try:
            stream_name = self.config.database.redis_stream_name
            
            # Check if stream exists
            try:
                await self.redis_client.xinfo_stream(stream_name)
                logger.debug(f"ğŸ“Š Stream '{stream_name}' exists")
            except ResponseError as e:
                if "no such key" in str(e).lower():
                    logger.info(f"ğŸ“Š Stream '{stream_name}' does not exist, will be created")
                else:
                    logger.error(f"âŒ Error checking stream: {e}")
                    return False
            
            # Create consumer group if it doesn't exist
            try:
                await self.redis_client.xgroup_create(
                    stream_name,
                    self.consumer_group,
                    id="$",  # Start from end of stream (only new messages)
                    mkstream=True
                )
                logger.info(f"âœ… Created consumer group: {self.consumer_group} (starting from stream end)")
                
            except ResponseError as e:
                if "BUSYGROUP" in str(e):
                    logger.info(f"ğŸ“Š Consumer group already exists: {self.consumer_group}")
                else:
                    logger.error(f"âŒ Failed to create consumer group: {e}")
                    return False
            
            # Verify consumer group exists
            try:
                groups = await self.redis_client.xinfo_groups(stream_name)
                group_exists = any(group['name'] == self.consumer_group for group in groups)
                
                if group_exists:
                    logger.info(f"âœ… Consumer group '{self.consumer_group}' verified")
                    
                    # Check if we need to reset consumer group position
                    if self.config.database.redis_consumer_group_reset:
                        try:
                            await self.redis_client.xgroup_setid(stream_name, self.consumer_group, "$")
                            logger.info(f"ğŸ”„ Reset consumer group '{self.consumer_group}' to stream end")
                        except Exception as e:
                            logger.warning(f"âš ï¸ Failed to reset consumer group position: {e}")
                    
                    return True
                else:
                    logger.error(f"âŒ Consumer group '{self.consumer_group}' not found after creation")
                    return False
                    
            except Exception as e:
                logger.error(f"âŒ Failed to verify consumer group: {e}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Error ensuring consumer group: {e}")
            return False
    
    async def disconnect(self):
        """Disconnect from Redis"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("ğŸ”Œ Disconnected from Redis")
    
    async def start_consuming(self):
        """Start consuming messages from Redis stream"""
        if not self.redis_client:
            logger.error("Redis client not connected")
            return
        
        self.running = True
        self.stats["start_time"] = datetime.now()
        logger.info(f"ğŸš€ Starting Redis stream consumption from {self.config.database.redis_stream_name}")
        
        while self.running:
            try:
                # Read messages from the stream
                messages = await self.redis_client.xreadgroup(
                    self.consumer_group,
                    self.consumer_name,
                    {self.config.database.redis_stream_name: ">"},
                    count=10,
                    block=1000  # Block for 1 second
                )
                
                if messages:
                    await self._process_messages(messages)
                    
            except ConnectionError as e:
                logger.error(f"ğŸ’¥ Redis connection lost: {e}")
                self.stats["last_error"] = f"Connection lost: {e}"
                await self._reconnect()
            except Exception as e:
                logger.error(f"âŒ Error consuming messages: {e}")
                self.stats["last_error"] = f"Consumption error: {e}"
                await asyncio.sleep(1)
    
    async def stop_consuming(self):
        """Stop consuming messages"""
        self.running = False
        logger.info("ğŸ›‘ Stopping Redis stream consumption")
    
    def _is_message_too_old(self, message_id: str) -> bool:
        """Check if message is older than configured threshold"""
        try:
            # Redis message ID format: timestamp-sequence (e.g., "1751695445548-0")
            timestamp_ms = int(message_id.split('-')[0])
            message_time = datetime.fromtimestamp(timestamp_ms / 1000)
            age_seconds = (datetime.now() - message_time).total_seconds()
            
            max_age = self.config.database.redis_message_max_age_seconds
            if age_seconds > max_age:
                logger.warning(f"â° Skipping old message {message_id} (age: {age_seconds:.1f}s > {max_age}s)")
                return True
            return False
            
        except (ValueError, IndexError) as e:
            logger.warning(f"âš ï¸ Invalid message ID format {message_id}: {e}")
            return False
    
    async def _process_messages(self, messages: List[tuple]):
        """Process messages from Redis stream"""
        for stream_name, stream_messages in messages:
            logger.info(f"ğŸ“¥ Processing {len(stream_messages)} messages from stream {stream_name}")
            
            for message_id, fields in stream_messages:
                message_processed = False
                self.stats["last_message_time"] = datetime.now()
                
                # Skip messages that are too old
                if self._is_message_too_old(message_id):
                    # Acknowledge old messages to prevent them from being redelivered
                    try:
                        await self.redis_client.xack(
                            self.config.database.redis_stream_name,
                            self.consumer_group,
                            message_id
                        )
                        logger.debug(f"âœ… Acknowledged and skipped old message {message_id}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Failed to acknowledge old message {message_id}: {e}")
                    continue
                
                try:
                    logger.debug(f"ğŸ”„ Processing message {message_id}: {fields}")
                    await self._handle_message(message_id, fields)
                    message_processed = True
                    self.stats["messages_processed"] += 1
                    self.stats["database_write_success"] += 1
                    logger.debug(f"âœ… Successfully processed message {message_id}")
                    
                except Exception as e:
                    logger.error(f"âŒ Error processing message {message_id}: {e}")
                    logger.error(f"ğŸ“‹ Message fields: {fields}")
                    self.stats["messages_failed"] += 1
                    self.stats["database_write_failures"] += 1
                    self.stats["last_error"] = f"Message processing error: {e}"
                    # Don't acknowledge failed messages - they'll be retried
                    continue
                
                # Only acknowledge if message was successfully processed
                if message_processed:
                    try:
                        await self.redis_client.xack(
                            self.config.database.redis_stream_name,
                            self.consumer_group,
                            message_id
                        )
                        logger.debug(f"âœ… Acknowledged message {message_id}")
                    except Exception as e:
                        logger.error(f"âŒ Failed to acknowledge message {message_id}: {e}")
                        self.stats["last_error"] = f"Message acknowledgment error: {e}"
    
    async def _handle_message(self, message_id: str, fields: Dict[str, str]):
        """Handle individual message based on type"""
        message_type = fields.get("type")
        run_id = fields.get("run_id")
        data_str = fields.get("data")
        timestamp = fields.get("timestamp")
        
        if not all([message_type, run_id, data_str]):
            logger.warning(f"Incomplete message: {fields}")
            return
        
        try:
            data = json.loads(data_str)
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON data: {e}")
            return
        
        logger.debug(f"ğŸ“¨ Processing {message_type} for run_id: {run_id}")
        
        if message_type == "live_stats":
            self.stats["message_types"]["live_stats"] += 1
            await self._process_live_stats(run_id, data, timestamp)
        elif message_type == "final_results":
            self.stats["message_types"]["final_results"] += 1
            await self._process_final_results(run_id, data, timestamp)
        elif message_type == "trade_event":
            self.stats["message_types"]["trade_event"] += 1
            await self._process_trade_event(run_id, data, timestamp)
        else:
            self.stats["message_types"]["unknown"] += 1
            logger.warning(f"Unknown message type: {message_type}")
    
    async def _process_live_stats(self, run_id: str, stats_data: Dict[str, Any], timestamp: str):
        """Process live statistics updates"""
        logger.info(f"ğŸ“Š Processing live stats for run_id: {run_id}")
        logger.debug(f"ğŸ“Š Live stats data: {stats_data}")
        
        try:
            # Update existing simulation run with live stats
            await self.database_service.update_simulation_live_stats(run_id, stats_data)
            logger.info(f"âœ… Successfully updated live stats for run_id: {run_id}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to update live stats for {run_id}: {e}")
            logger.error(f"ğŸ“‹ Stats data: {stats_data}")
            raise  # Re-raise to prevent message acknowledgment
    
    async def _process_final_results(self, run_id: str, results_data: Dict[str, Any], timestamp: str):
        """Process final simulation results"""
        logger.info(f"ğŸ Processing final results for run_id: {run_id}")
        logger.debug(f"ğŸ Final results data: {results_data}")
        
        try:
            # Update simulation run with final results
            await self.database_service.update_simulation_final_results(run_id, results_data)
            logger.info(f"âœ… Successfully processed final results for run_id: {run_id}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to process final results for {run_id}: {e}")
            logger.error(f"ğŸ“‹ Results data: {results_data}")
            raise  # Re-raise to prevent message acknowledgment
    
    async def _process_trade_event(self, run_id: str, trade_data: Dict[str, Any], timestamp: str):
        """Process individual trade events"""
        logger.info(f"ğŸ’± Processing trade event for run_id: {run_id}")
        logger.debug(f"ğŸ’± Trade data: {trade_data}")
        
        try:
            # Store individual trade
            await self.database_service.store_trade_event(run_id, trade_data)
            logger.info(f"âœ… Successfully stored trade event for run_id: {run_id}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to store trade event for {run_id}: {e}")
            logger.error(f"ğŸ“‹ Trade data: {trade_data}")
            raise  # Re-raise to prevent message acknowledgment
    
    async def _reconnect(self):
        """Attempt to reconnect to Redis"""
        logger.info("ğŸ”„ Attempting to reconnect to Redis...")
        await asyncio.sleep(5)  # Wait before reconnecting
        
        try:
            await self.disconnect()
            if await self.connect():
                logger.info("âœ… Reconnected to Redis successfully")
            else:
                logger.error("âŒ Failed to reconnect to Redis")
        except Exception as e:
            logger.error(f"âŒ Reconnection failed: {e}")
    
    async def get_stream_info(self) -> Dict[str, Any]:
        """Get information about the Redis stream"""
        if not self.redis_client:
            return {}
        
        try:
            stream_info = await self.redis_client.xinfo_stream(self.config.database.redis_stream_name)
            group_info = await self.redis_client.xinfo_groups(self.config.database.redis_stream_name)
            
            return {
                "stream_info": stream_info,
                "groups": group_info
            }
        except Exception as e:
            logger.error(f"Failed to get stream info: {e}")
            return {}
    
    def get_consumer_stats(self) -> Dict[str, Any]:
        """Get consumer statistics"""
        stats = self.stats.copy()
        
        # Add computed statistics
        if stats["start_time"]:
            uptime = datetime.now() - stats["start_time"]
            stats["uptime_seconds"] = uptime.total_seconds()
            stats["uptime_human"] = str(uptime)
            
            # Calculate rates
            if stats["uptime_seconds"] > 0:
                stats["messages_per_second"] = stats["messages_processed"] / stats["uptime_seconds"]
                stats["success_rate"] = (
                    stats["database_write_success"] / 
                    (stats["database_write_success"] + stats["database_write_failures"]) 
                    if (stats["database_write_success"] + stats["database_write_failures"]) > 0 else 0
                )
        
        stats["is_running"] = self.running
        stats["connected"] = self.redis_client is not None
        
        # Format timestamps
        if stats["last_message_time"]:
            stats["last_message_time"] = stats["last_message_time"].isoformat()
        if stats["start_time"]:
            stats["start_time"] = stats["start_time"].isoformat()
        
        return stats